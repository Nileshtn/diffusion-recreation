{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 1, 28, 28)\n",
    "t = torch.randn(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t[:, :, None, None]\n",
    "t = t.expand(-1, -1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.1204, -1.9200, -0.8335,  ..., -3.0485, -1.1710, -1.8532],\n",
       "          [-4.4841, -0.3954, -4.5222,  ..., -1.3759, -0.2037, -1.6805],\n",
       "          [-0.5427, -1.2588, -1.9890,  ..., -1.8176, -2.5087, -1.5693],\n",
       "          ...,\n",
       "          [-1.6859,  0.2088, -3.3992,  ..., -3.4385, -2.7556, -2.9025],\n",
       "          [ 0.2439,  0.1677, -2.8887,  ..., -2.3116, -3.9316, -2.1073],\n",
       "          [-2.3236, -1.0756, -1.2229,  ..., -3.7300, -0.6277, -0.7658]],\n",
       "\n",
       "         [[-1.3499, -1.1495, -0.0629,  ..., -2.2780, -0.4005, -1.0827],\n",
       "          [-3.7136,  0.3751, -3.7517,  ..., -0.6054,  0.5668, -0.9100],\n",
       "          [ 0.2278, -0.4883, -1.2185,  ..., -1.0471, -1.7382, -0.7988],\n",
       "          ...,\n",
       "          [-0.9154,  0.9793, -2.6287,  ..., -2.6680, -1.9851, -2.1320],\n",
       "          [ 1.0144,  0.9382, -2.1182,  ..., -1.5411, -3.1611, -1.3368],\n",
       "          [-1.5531, -0.3051, -0.4524,  ..., -2.9594,  0.1428,  0.0047]],\n",
       "\n",
       "         [[-1.2268, -1.0264,  0.0602,  ..., -2.1549, -0.2774, -0.9596],\n",
       "          [-3.5905,  0.4982, -3.6286,  ..., -0.4823,  0.6899, -0.7869],\n",
       "          [ 0.3509, -0.3652, -1.0954,  ..., -0.9240, -1.6151, -0.6757],\n",
       "          ...,\n",
       "          [-0.7923,  1.1024, -2.5056,  ..., -2.5449, -1.8620, -2.0089],\n",
       "          [ 1.1375,  1.0613, -1.9951,  ..., -1.4180, -3.0380, -1.2137],\n",
       "          [-1.4300, -0.1820, -0.3293,  ..., -2.8363,  0.2659,  0.1278]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4957,  0.6962,  1.7827,  ..., -0.4324,  1.4452,  0.7629],\n",
       "          [-1.8680,  2.2208, -1.9060,  ...,  1.2402,  2.4124,  0.9357],\n",
       "          [ 2.0734,  1.3573,  0.6271,  ...,  0.7986,  0.1075,  1.0468],\n",
       "          ...,\n",
       "          [ 0.9303,  2.8250, -0.7831,  ..., -0.8223, -0.1395, -0.2863],\n",
       "          [ 2.8600,  2.7839, -0.2726,  ...,  0.3045, -1.3154,  0.5088],\n",
       "          [ 0.2925,  1.5405,  1.3933,  ..., -1.1138,  1.9884,  1.8503]],\n",
       "\n",
       "         [[ 1.4474,  1.6479,  2.7344,  ...,  0.5194,  2.3969,  1.7146],\n",
       "          [-0.9163,  3.1725, -0.9543,  ...,  2.1920,  3.3641,  1.8874],\n",
       "          [ 3.0252,  2.3091,  1.5789,  ...,  1.7503,  1.0592,  1.9986],\n",
       "          ...,\n",
       "          [ 1.8820,  3.7767,  0.1686,  ...,  0.1294,  0.8123,  0.6654],\n",
       "          [ 3.8118,  3.7356,  0.6792,  ...,  1.2563, -0.3637,  1.4605],\n",
       "          [ 1.2443,  2.4922,  2.3450,  ..., -0.1621,  2.9401,  2.8020]],\n",
       "\n",
       "         [[ 0.4768,  0.6772,  1.7637,  ..., -0.4513,  1.4262,  0.7440],\n",
       "          [-1.8869,  2.2018, -1.9250,  ...,  1.2213,  2.3935,  0.9167],\n",
       "          [ 2.0545,  1.3384,  0.6082,  ...,  0.7796,  0.0885,  1.0279],\n",
       "          ...,\n",
       "          [ 0.9113,  2.8060, -0.8020,  ..., -0.8413, -0.1584, -0.3053],\n",
       "          [ 2.8411,  2.7649, -0.2915,  ...,  0.2856, -1.3344,  0.4899],\n",
       "          [ 0.2736,  1.5216,  1.3743,  ..., -1.1328,  1.9695,  1.8314]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Up, self).__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x = self.up(x1)\n",
    "        diffY = x2.size()[2] - x.size()[2]\n",
    "        diffX = x2.size()[3] - x.size()[3]\n",
    "        x = F.pad(x, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.down1 = DoubleConv(in_channels, 64)\n",
    "        self.down2 = Down(64, 128)\n",
    "        self.down3 = Down(128, 256)\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "        self.up1 = Up(512, 256)\n",
    "        self.up2 = Up(256, 128)\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x = self.bottleneck(x3)\n",
    "        x = self.up1(x, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up3(x, x1)\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, 1, 256, 256)\n",
    "b = unet(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
